{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b2da36-e313-4380-9770-12880bc38ccf",
   "metadata": {},
   "source": [
    "## **Evaluation Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf5e51c-3926-4e54-8a60-1ea1dc0a7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [{\"prompt\": \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nyou are a cyber security expert that can detect vulnerable line numbers from the contract as well as vulnerableCode, vulnerabilityReason, potentialSecurityRisk, and fixedCode.\\nfind all tiemstamp dependency vulnerabilities  and detect vulnerable line numbers from the contract as well as vulnerableCode, vulnerabilityReason, potentialSecurityRisk, and fixedCode based on the instruction.\\n\\n1: \\n2: \\n3: function rescueTokens(uint _pollID) public {\\n4: require(isExpired(pollMap[_pollID].revealEndDate));\\n5: require(dllMap[msg.sender].contains(_pollID));\\n6: \\n7: dllMap[msg.sender].remove(_pollID);\\n8: emit _TokensRescued(_pollID, msg.sender);\\n9: }<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", \"predict\": \"{\\\"vulnerableLines\\\": \\\"\\\", \\\"vulnerableCode\\\": [], \\\"vulnerabilityReason\\\": \\\"\\\", \\\"potentialSecurityRisk\\\": \\\"\\\", \\\"fixedCode\\\": \\\"\\\"}\", \"label\": \"{\\\"vulnerableLines\\\": \\\"\\\", \\\"vulnerableCode\\\": [], \\\"vulnerabilityReason\\\": \\\"\\\", \\\"potentialSecurityRisk\\\": \\\"\\\", \\\"fixedCode\\\": \\\"\\\"}\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92ba8ff-4890-4e6c-90f1-b33cc43d57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= [{\"prompt\": \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nyou are a cyber security expert that can detect vulnerable line numbers from the contract as well as vulnerableCode, vulnerabilityReason, potentialSecurityRisk, and fixedCode.\\nfind all tiemstamp dependency vulnerabilities  and detect vulnerable line numbers from the contract as well as vulnerableCode, vulnerabilityReason, potentialSecurityRisk, and fixedCode based on the instruction.\\n\\n1: address winner_38;\\n2: function play_38(uint startTime) public {\\n3: if (startTime + (5 * 1 days) == block.timestamp){\\n4: winner_38 = msg.sender;}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\", \"predict\": \"{\\\"vulnerableLines\\\": \\\"1-4\\\", \\\"vulnerableCode\\\": [\\\"address winner_38;\\\", \\\"function play_38(uint startTime) public {\\\", \\\"    if (startTime + (5 * 1 days) == block.timestamp){\\\", \\\"        winner_38 = msg.sender;}}\\\"], \\\"vulnerabilityReason\\\": \\\"The function play_38 uses block.timestamp to compare against a calculated future time. This can lead to exploiters manipulating the block timestamp to gain an unintended advantage.\\\", \\\"potentialSecurityRisk\\\": \\\"A miner could set the timestamp to match the winning condition, allowing them or a colluding party to win instantly, leading to potential loss of funds for other players.\\\", \\\"fixedCode\\\": \\\"function play_38(uint startTime) public { require(startTime + (5 * 1 days) <= block.timestamp, 'Game not started or already finished'); winner_38 = msg.sender; }\\\"}\", \"label\": \"{\\\"vulnerableLines\\\": \\\"1-4\\\", \\\"vulnerableCode\\\": [\\\"address winner_38;\\\", \\\"function play_38(uint startTime) public {\\\", \\\"    if (startTime + (5 * 1 days) == block.timestamp){\\\", \\\"        winner_38 = msg.sender;}}\\\"], \\\"vulnerabilityReason\\\": \\\"The function play_38 uses block.timestamp in the condition for setting a winner, making it susceptible to manipulation by a miner.\\\", \\\"potentialSecurityRisk\\\": \\\"By crafting a block with a manipulated timestamp, a miner could unfairly claim the winner's position, leading to loss or unfair advantage.\\\", \\\"fixedCode\\\": \\\"function play_38(uint startTime) public { require(startTime + (5 * 1 days) <= block.timestamp, 'Game not started or already finished'); winner_38 = msg.sender; }\\\"}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3edb8c82-21b7-48c4-a199-1d2bb8699ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vulnerableLines\": \"\", \"vulnerableCode\": [], \"vulnerabilityReason\": \"\", \"potentialSecurityRisk\": \"\", \"fixedCode\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "print(a[0]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5723fa5-7422-45d2-b14e-0aba7a4d7d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vulnerableLines\": \"1-4\", \"vulnerableCode\": [\"address winner_38;\", \"function play_38(uint startTime) public {\", \"    if (startTime + (5 * 1 days) == block.timestamp){\", \"        winner_38 = msg.sender;}}\"], \"vulnerabilityReason\": \"The function play_38 uses block.timestamp to compare against a calculated future time. This can lead to exploiters manipulating the block timestamp to gain an unintended advantage.\", \"potentialSecurityRisk\": \"A miner could set the timestamp to match the winning condition, allowing them or a colluding party to win instantly, leading to potential loss of funds for other players.\", \"fixedCode\": \"function play_38(uint startTime) public { require(startTime + (5 * 1 days) <= block.timestamp, 'Game not started or already finished'); winner_38 = msg.sender; }\"}\n"
     ]
    }
   ],
   "source": [
    "print(b[0]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb30e98-836f-477d-8730-d80b46a946c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vulnerableLines\": \"\", \"vulnerableCode\": [], \"vulnerabilityReason\": \"\", \"potentialSecurityRisk\": \"\", \"fixedCode\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print (a[i]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9517910f-ccef-4362-bc05-fc8d3a555aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vulnerableLines\": \"\", \"vulnerableCode\": [], \"vulnerabilityReason\": \"\", \"potentialSecurityRisk\": \"\", \"fixedCode\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "print (a[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12152630-b213-4b30-949f-af35dae65a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "431076d1-713c-4bf3-80e8-32b1ad1c6566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vulnerableLines\": \"\", \"vulnerableCode\": [], \"vulnerabilityReason\": \"\", \"potentialSecurityRisk\": \"\", \"fixedCode\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "with open(\"generated_predictions_all_llama31.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        a.append(json.loads(line))\n",
    "print(a[12]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cdbb0ae-1523-4908-91b4-82e7604424a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"vulnerableLines\": \"\", \"vulnerableCode\": [], \"vulnerabilityReason\": \"\", \"potentialSecurityRisk\": \"\", \"fixedCode\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "b=[]\n",
    "with open(\"generated_predictions_all_llama31_2.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        b.append(json.loads(line))\n",
    "print(b[20]['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d41ab-808a-406c-892d-72b24599255c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bdcb06a-1b8e-46a8-b374-41507698dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f08035c5-11b3-4f08-afd0-4b0afdf237dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "with open(\"generated_predictions_all_llama31_3.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        a.append(json.loads(line))\n",
    "\n",
    "def eval_metrics(vul_range):\n",
    "    if not vul_range or vul_range.strip() == \"\":\n",
    "        return set()\n",
    "    parts = vul_range.split('-')\n",
    "    if len(parts) == 1:\n",
    "        return set([int(parts[0])])\n",
    "    return set(range(int(parts[0]), int(parts[1]) + 1))\n",
    "\n",
    "def parse_field(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {\"vulnerableLines\": \"\"}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"vulnerableLines\": \"\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c3eaaa5-5683-405a-ab70-99205eef1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "results = []\n",
    "\n",
    "for i, sample in enumerate(a):\n",
    "    label_dict = parse_field(sample.get(\"label\", \"\"))\n",
    "    pred_dict = parse_field(sample.get(\"predict\", \"\"))\n",
    "\n",
    "    label_range_str = label_dict.get(\"vulnerableLines\", \"\")\n",
    "    pred_range_str = pred_dict.get(\"vulnerableLines\", \"\")\n",
    "\n",
    "    label_lines = eval_metrics(label_range_str)\n",
    "    pred_lines = eval_metrics(pred_range_str)\n",
    "    # print(label_lines)\n",
    "    # print(pred_lines)\n",
    "    # print(label_lines & pred_lines)\n",
    "    if not label_lines and not pred_lines:\n",
    "        y_true.append(0)\n",
    "        y_pred.append(0)\n",
    "        results.append({\"id\": i, \"result\": \"TN\"})\n",
    "    elif label_lines and not pred_lines:\n",
    "        y_true.append(1)\n",
    "        y_pred.append(0)\n",
    "        results.append({\"id\": i, \"result\": \"FN\"})\n",
    "    elif not label_lines and pred_lines:\n",
    "        y_true.append(0)\n",
    "        y_pred.append(1)\n",
    "        results.append({\"id\": i, \"result\": \"FP\"})\n",
    "    else:\n",
    "        overlap = label_lines & pred_lines\n",
    "        if overlap:\n",
    "            y_true.append(1)\n",
    "            y_pred.append(1)\n",
    "            results.append({\"id\": i, \"result\": \"TP\"})\n",
    "        else:\n",
    "            y_true.append(1)\n",
    "            y_pred.append(0)\n",
    "            results.append({\"id\": i, \"result\": \"FN (no overlap)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3e2c27-a46f-4063-8f04-cedb2d46d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(y_true)\n",
    "# print( y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "232a54de-d8c7-4a15-9e42-5bcd29e690ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy : 0.8489\n",
      "Precision: 0.9268\n",
      "Recall   : 0.8034\n",
      "F1-score : 0.8607\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "# Optional: Save results\n",
    "with open(\"prediction_eval_results_3.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r) + \"\\n\")\n",
    "        #print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972cd2d-c344-4a54-9dc4-ac369e94c479",
   "metadata": {},
   "source": [
    "## **Evaluation of Generated Text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837c625-20c0-4669-8ace-dc46eb96d5c3",
   "metadata": {},
   "source": [
    "## Using Rouge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6cb70c-f293-40c4-b8fc-36ddad99f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge-score bert-score nltk --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab6e4955-fafb-48d8-b5a6-0ea6a6b24b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-L Score: 0.3118\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "for sample in a[:20]:\n",
    "    label = safe_parse_json(sample.get(\"label\", \"\"))\n",
    "    pred = safe_parse_json(sample.get(\"predict\", \"\"))\n",
    "\n",
    "    ref = label.get(\"vulnerabilityReason\", \"\")\n",
    "    hyp = pred.get(\"vulnerabilityReason\", \"\")\n",
    "\n",
    "    score = rouge.score(ref, hyp)\n",
    "    rouge_scores.append(score['rougeL'].fmeasure)\n",
    "\n",
    "print(f\"Average ROUGE-L Score: {sum(rouge_scores)/len(rouge_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb81e4eb-da6f-49ef-9971-dbdc00478d64",
   "metadata": {},
   "source": [
    "## Using Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd0d33db-6ffd-479b-a3f3-d738975f81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\erfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "nltk.download('punkt')\n",
    "\n",
    "def compute_bleu(reference, prediction):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    reference_tokens = [nltk.word_tokenize(reference.lower(), preserve_line=True)]\n",
    "    prediction_tokens = nltk.word_tokenize(prediction.lower(), preserve_line=True)\n",
    "    return sentence_bleu(reference_tokens, prediction_tokens, smoothing_function=smoothie)\n",
    "\n",
    "# Handle empty strings and malformed JSON\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "# Compute BLEU scores\n",
    "bleu_scores = []\n",
    "\n",
    "for sample in a[:20]:\n",
    "    label = safe_parse_json(sample.get(\"label\", \"\"))\n",
    "    pred = safe_parse_json(sample.get(\"predict\", \"\"))\n",
    "\n",
    "    ref = label.get(\"vulnerabilityReason\", \"\")\n",
    "    hyp = pred.get(\"vulnerabilityReason\", \"\")\n",
    "\n",
    "    bleu_scores.append(compute_bleu(ref, hyp))\n",
    "\n",
    "print(f\"Average BLEU Score: {sum(bleu_scores)/len(bleu_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54beb3b3-45c4-4a96-83c5-20e8517d1072",
   "metadata": {},
   "source": [
    "##  Embeding Consistency Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546ead01-f4ad-46ef-9400-ce8d5cea42d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\erfan\\OneDrive - polymtlus\\Apps\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\erfan\\OneDrive - polymtlus\\Apps\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\erfan\\OneDrive - polymtlus\\Apps\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ff17caf8-aba2-4e07-b56f-f4ec5c0c2aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Consistency Score (Embedding Similarity): 0.4008\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "\n",
    "# Load lightweight sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Safe JSON parser\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "# Compute semantic similarity between vulnerableCode and vulnerabilityReason\n",
    "consistency_scores = []\n",
    "\n",
    "for sample in a[:20]:  # or all: a\n",
    "    label = safe_parse_json(sample.get(\"label\", \"\"))\n",
    "    code_lines = label.get(\"vulnerableCode\", [])\n",
    "    reason = label.get(\"vulnerabilityReason\", \"\")\n",
    "\n",
    "    if not code_lines or not reason.strip():\n",
    "        continue\n",
    "\n",
    "    code_text = \"\\n\".join(code_lines)\n",
    "\n",
    "    code_emb = model.encode(code_text, convert_to_tensor=True)\n",
    "    reason_emb = model.encode(reason, convert_to_tensor=True)\n",
    "\n",
    "    score = util.cos_sim(code_emb, reason_emb).item()\n",
    "    consistency_scores.append(score)\n",
    "\n",
    "# Report\n",
    "avg_score = sum(consistency_scores) / len(consistency_scores) if consistency_scores else 0\n",
    "print(f\"Average Consistency Score (Embedding Similarity): {avg_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd941db-6861-4b48-b855-a73ce96ad577",
   "metadata": {},
   "source": [
    "## Factual consistency of **\"VulnerabilityReason\"** of prediction and ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64edbbd4-4652-4ab7-b6db-dd03f21ee1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Factual Consistency Score (Label ↔ Predict Reason): 0.7625\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "\n",
    "# Load lightweight sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Safe JSON parser\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "# Compute semantic similarity between label and predicted vulnerabilityReason\n",
    "factual_scores = []\n",
    "\n",
    "for sample in a:  # Use all samples\n",
    "    label = safe_parse_json(sample.get(\"label\", \"\"))\n",
    "    pred = safe_parse_json(sample.get(\"predict\", \"\"))\n",
    "\n",
    "    label_reason = label.get(\"vulnerabilityReason\", \"\")\n",
    "    pred_reason = pred.get(\"vulnerabilityReason\", \"\")\n",
    "\n",
    "    if not label_reason.strip() or not pred_reason.strip():\n",
    "        continue\n",
    "\n",
    "    label_emb = model.encode(label_reason, convert_to_tensor=True)\n",
    "    pred_emb = model.encode(pred_reason, convert_to_tensor=True)\n",
    "\n",
    "    score = util.cos_sim(label_emb, pred_emb).item()\n",
    "    factual_scores.append(score)\n",
    "\n",
    "# Report\n",
    "avg_score = sum(factual_scores) / len(factual_scores) if factual_scores else 0\n",
    "print(f\"Average Factual Consistency Score (Label ↔ Predict Reason): {avg_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88def63a-99b7-42c2-989f-11d7acb582c4",
   "metadata": {},
   "source": [
    "## Code-Aware Similarity (VulnerableCode <--> FixedCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a21a2de-c970-42b2-a4d0-c58f4a6d91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Code-Aware Similarity (Vulnerable ↔ Fixed Code): 0.8646\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "\n",
    "# Load lightweight sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Safe JSON parser\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "# Compute semantic similarity between vulnerableCode and fixedCode\n",
    "code_similarity_scores = []\n",
    "\n",
    "for sample in a:  # Use all samples\n",
    "    pred = safe_parse_json(sample.get(\"predict\", \"\"))\n",
    "    \n",
    "    vuln_code = \"\\n\".join(pred.get(\"vulnerableCode\", []))\n",
    "    fixed_code = pred.get(\"fixedCode\", \"\")\n",
    "\n",
    "    if not vuln_code.strip() or not fixed_code.strip():\n",
    "        continue\n",
    "\n",
    "    vuln_emb = model.encode(vuln_code, convert_to_tensor=True)\n",
    "    fixed_emb = model.encode(fixed_code, convert_to_tensor=True)\n",
    "\n",
    "    score = util.cos_sim(vuln_emb, fixed_emb).item()\n",
    "    code_similarity_scores.append(score)\n",
    "\n",
    "# Report\n",
    "avg_score = sum(code_similarity_scores) / len(code_similarity_scores) if code_similarity_scores else 0\n",
    "print(f\"Average Code-Aware Similarity (Vulnerable ↔ Fixed Code): {avg_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f65d4a-7c60-4101-85c7-3050985cf58a",
   "metadata": {},
   "source": [
    "## **Risk Assessment Alignment**  (Reason <--> Risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d097a5f-cf1f-4553-be36-a68281003d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Risk Assessment Alignment (Reason ↔ Risk): 0.5405\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "\n",
    "# Load lightweight sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Safe JSON parser\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "# Compute semantic similarity between vulnerabilityReason and potentialSecurityRisk\n",
    "risk_alignment_scores = []\n",
    "\n",
    "for sample in a:  # Use all samples\n",
    "    pred = safe_parse_json(sample.get(\"predict\", \"\"))\n",
    "    \n",
    "    reason = pred.get(\"vulnerabilityReason\", \"\")\n",
    "    risk = pred.get(\"potentialSecurityRisk\", \"\")\n",
    "\n",
    "    if not reason.strip() or not risk.strip():\n",
    "        continue\n",
    "\n",
    "    reason_emb = model.encode(reason, convert_to_tensor=True)\n",
    "    risk_emb = model.encode(risk, convert_to_tensor=True)\n",
    "\n",
    "    score = util.cos_sim(reason_emb, risk_emb).item()\n",
    "    risk_alignment_scores.append(score)\n",
    "\n",
    "# Report\n",
    "avg_score = sum(risk_alignment_scores) / len(risk_alignment_scores) if risk_alignment_scores else 0\n",
    "print(f\"Average Risk Assessment Alignment (Reason ↔ Risk): {avg_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092e0b9-ac54-45d4-9d23-e2114aa8103f",
   "metadata": {},
   "source": [
    "## **OpenAI's embedding model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc70666-c6b7-4265-a2c5-d04c2e9cb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe08c588-97b2-42ad-9485-1d4a592814e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24e360f5-1097-413d-bf05-bd5d3a8b5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d12400f2-514a-4c56-98a3-60cf2e6257ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"generated_predictions_all_llama31.jsonl\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "def safe_parse_json(field):\n",
    "    if not field or field.strip() == \"\":\n",
    "        return {}\n",
    "    if isinstance(field, dict):\n",
    "        return field\n",
    "    try:\n",
    "        return json.loads(field)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    response = openai.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84355c12-33f5-4338-bff8-744803a4f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reasons = []\n",
    "index_map = []\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    entry = json.loads(line)\n",
    "    pred = safe_parse_json(entry.get(\"predict\", \"\"))\n",
    "    label = safe_parse_json(entry.get(\"label\", \"\"))\n",
    "\n",
    "    pred_reason = pred.get(\"potentialSecurityRisk\", \"\").strip()\n",
    "    label_reason = label.get(\"potentialSecurityRisk\", \"\").strip()\n",
    "\n",
    "    if pred_reason and label_reason:\n",
    "        all_reasons.extend([pred_reason, label_reason])\n",
    "        index_map.append(i)\n",
    "\n",
    "# Get all embeddings in one batch call\n",
    "response = openai.embeddings.create(\n",
    "    input=all_reasons,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "embeddings = [item.embedding for item in response.data]\n",
    "\n",
    "# Compute similarity\n",
    "similarity_scores = []\n",
    "for i, idx in enumerate(index_map):\n",
    "    emb_pred = embeddings[2 * i]\n",
    "    emb_label = embeddings[2 * i + 1]\n",
    "    score = cosine_similarity([emb_pred], [emb_label])[0][0]\n",
    "\n",
    "    entry = json.loads(lines[idx])\n",
    "    pred = safe_parse_json(entry.get(\"predict\", \"\"))\n",
    "    label = safe_parse_json(entry.get(\"label\", \"\"))\n",
    "\n",
    "    similarity_scores.append({\n",
    "        \"predict\": pred.get(\"potentialSecurityRisk\", \"\"),\n",
    "        \"label\": label.get(\"potentialSecurityRisk\", \"\"),\n",
    "        \"similarity\": score\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dde87009-15ce-4f13-849a-0a7072c85834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Semantic Similarity:0.8940\n"
     ]
    }
   ],
   "source": [
    "# Print top 5 results\n",
    "sum_similarity = 0\n",
    "for item in similarity_scores[:]:\n",
    "    # print(\"Prediction:\", item[\"predict\"])\n",
    "    # print(\"Label     :\", item[\"label\"])\n",
    "    # print(f\"Similarity Score: {item['similarity']:.4f}\")\n",
    "    # print(\"=\"*50)\n",
    "    sum_similarity = sum_similarity + item[\"similarity\"]\n",
    "avg_score = sum_similarity / len(similarity_scores)\n",
    "print(f\"Average Semantic Similarity:{avg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b5949-6525-456c-8feb-b4ff06ba2538",
   "metadata": {},
   "source": [
    "## Average Semantic Similarity: 77.23 between vulnerabilityReason of the prediction and the label\n",
    "## Average Semantic Similarity: 73.16 between potentialSecurityRisk of the prediction and the label\n",
    "## Average Semantic Similarity: 89.40 between fixedCode of the prediction and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2e3c7-f9d3-4567-a11f-dcbcd40835ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29c04de-607e-40d2-916d-7a19d6aa8c0b",
   "metadata": {},
   "source": [
    "## vscode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf47b95b-08b2-4ca9-9101-b966326c0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "\n",
    "  {\n",
    "     \"vulnerableLines\": \"6-10\",\n",
    "     \"vulnerabilityReason\": \"This vulnerability occurs as integer underflow vulnerability. 'userBalanceToken[msg.sender]' is not checked if it is zero before sending token.\",\n",
    "     \"potentialSecurityRisk\": \"An attacker may withdraw more balance than they own by send operation, this can lead to making balance of 'userBalanceToken[msg.sender]' to underflow and turn to be a very large number and enabling attacker to withdraw nearly infinite tokens.\",\n",
    "     \"fixedCode\": \"function withdrawBalanceToken() public{ if(userBalanceToken[msg.sender] > 0) { if( ! (msg.sender.send(userBalanceToken[msg.sender]) ) ){ revert(); } userBalanceToken[msg.sender] = 0; } }\"\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3b10f1d-9550-434a-bc60-9cd462bf5162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This vulnerability occurs as integer underflow vulnerability. 'userBalanceToken[msg.sender]' is not checked if it is zero before sending token.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "predict = a[0]['vulnerabilityReason']\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3abf8-d067-4dc0-bb57-93b88c8a09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Read from the .txt file\n",
    "with open(\"/mnt/data/contract_4.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Regex pattern to extract JSON array (used under === Time Dependency ===)\n",
    "pattern = r\"\\[\\s*{.*?}\\s*]\"\n",
    "\n",
    "# Find JSON block(s) — assume the first match is the vulnerability data you want\n",
    "matches = re.findall(pattern, content, flags=re.DOTALL)\n",
    "\n",
    "if matches:\n",
    "    vulnerability_data = json.loads(matches[0])\n",
    "\n",
    "    # Save it into a JSON file\n",
    "    with open(\"/mnt/data/contract_4_parsed.json\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "        json.dump(vulnerability_data, out_file, indent=2)\n",
    "    print(\" JSON saved to 'contract_4_parsed.json'\")\n",
    "else:\n",
    "    print(\" No JSON array found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15ef94b8-d849-419c-b1b3-bee61cd37287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: The function 'withdrawBalanceToken()' allows for the possible occurrence of a re-entrancy attack by calling an external contract (i.e msg.sender.send()). Moreover, it subtracts the balance after calling the external contract, which can lead to underflows if the subtraction is larger than the balance.\n",
      "Factual Consistency Score: 0.5487\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "\n",
    "# Load predicted vulnerabilityReason\n",
    "predict = a[0]['vulnerabilityReason'].strip()\n",
    "# print(\"Predict:\", predict)\n",
    "\n",
    "# Load label from JSON file\n",
    "with open(\"contract_1.json\", 'r', encoding='utf-8') as file:\n",
    "    label_json = json.load(file)\n",
    "\n",
    "# Extract and strip the vulnerabilityReason from the label\n",
    "label = label_json[0].get('vulnerabilityReason', '').strip()\n",
    "print(\"Label:\", label)\n",
    "\n",
    "# Load sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compare if both are non-empty\n",
    "if predict and label:\n",
    "    pred_emb = model.encode(predict, convert_to_tensor=True)\n",
    "    label_emb = model.encode(label, convert_to_tensor=True)\n",
    "    score = util.cos_sim(pred_emb, label_emb).item()\n",
    "    print(f\"Factual Consistency Score: {score:.4f}\")\n",
    "else:\n",
    "    print(\"Missing vulnerabilityReason in predict or label.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd6829-360d-490f-b784-3f10b5bee42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720c023-14ba-44ee-a68f-cadaaa348d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f568a-9578-4c16-8607-37bb213a42cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb996487-f928-4b77-bbea-7bfef244db65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

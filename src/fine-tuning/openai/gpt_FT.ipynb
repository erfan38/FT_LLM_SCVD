{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b888771-ed56-4ac0-b114-24d123e0cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd407a5-ce9b-46d4-b67a-32d1581f052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c834241-86c5-49ce-967a-06c021e8f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpaca_to_gpt(alpaca_dict):\n",
    "    instruction = alpaca_dict.get(\"instruction\", \"\").strip()\n",
    "    input_content = alpaca_dict.get(\"input\", \"\").strip()\n",
    "    output = alpaca_dict.get(\"output\", \"\").strip()\n",
    "\n",
    "    messages = []\n",
    "    if instruction:\n",
    "        messages.append({\"role\": \"system\", \"content\": instruction})\n",
    "    if input_content:\n",
    "        messages.append({\"role\": \"user\", \"content\": input_content})\n",
    "    if output:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": output})\n",
    "    \n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"alpaca_train_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    alpaca_train_data = json.load(f)\n",
    "    gpt_train_data = [alpaca_to_gpt(data) for data in alpaca_train_data]\n",
    "    \n",
    "with open(\"alpaca_valid_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    alpaca_valid_data = json.load(f)\n",
    "    gpt_valid_data = [alpaca_to_gpt(data) for data in alpaca_valid_data]\n",
    "    \n",
    "with open(\"alpaca_test_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    alpaca_test_data = json.load(f)\n",
    "    gpt_test_data = [alpaca_to_gpt(data) for data in alpaca_test_data]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21b264-53a1-4084-8db9-8ed85e040dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9be141-d64c-4d73-ac3e-b6282f9c6a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 949, valid: 126, test: 191\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"oai_train_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gpt_train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"oai_valid_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gpt_valid_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(\"oai_test_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(gpt_test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"train: {len(gpt_train_data)}, valid: {len(gpt_valid_data)}, test: {len(gpt_test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37ffec18-d493-4722-aafe-d56f57c21af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to JSONL and saved to oai_train_data1.jsonl\n",
      "Converted to JSONL and saved to oai_valid_data1.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_pretty_json_to_jsonl(pretty_json_path, output_jsonl_path):\n",
    "    with open(pretty_json_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "        data = json.load(infile)  # Load the entire JSON array\n",
    "\n",
    "    with open(output_jsonl_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for obj in data:\n",
    "            json_line = json.dumps(obj)\n",
    "            outfile.write(json_line + \"\\n\")\n",
    "\n",
    "    print(f\"Converted to JSONL and saved to {output_jsonl_path}\")\n",
    "convert_pretty_json_to_jsonl('oai_train_data.jsonl', 'oai_train_data1.jsonl')\n",
    "convert_pretty_json_to_jsonl('oai_valid_data.jsonl', 'oai_valid_data1.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed8fb6bd-4931-4262-ba3f-238e1e5bcf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All lines are valid.\n",
      "✅ All lines are valid.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def validate_openai_chat_jsonl(filepath):\n",
    "    errors = []\n",
    "    valid_roles = {\"system\", \"user\", \"assistant\"}\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line_num, line in enumerate(f, start=1):\n",
    "            try:\n",
    "                # Try to parse the line as JSON\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                errors.append(f\"Line {line_num}: Invalid JSON - {e}\")\n",
    "                continue\n",
    "\n",
    "            # Check for 'messages' key\n",
    "            if \"messages\" not in obj:\n",
    "                errors.append(f\"Line {line_num}: Missing 'messages' key.\")\n",
    "                continue\n",
    "\n",
    "            messages = obj[\"messages\"]\n",
    "\n",
    "            if not isinstance(messages, list):\n",
    "                errors.append(f\"Line {line_num}: 'messages' should be a list.\")\n",
    "                continue\n",
    "\n",
    "            for i, msg in enumerate(messages):\n",
    "                if not isinstance(msg, dict):\n",
    "                    errors.append(f\"Line {line_num}, message {i+1}: Message is not a dict.\")\n",
    "                    continue\n",
    "                if \"role\" not in msg:\n",
    "                    errors.append(f\"Line {line_num}, message {i+1}: Missing 'role'.\")\n",
    "                elif msg[\"role\"] not in valid_roles:\n",
    "                    errors.append(f\"Line {line_num}, message {i+1}: Invalid role '{msg['role']}'.\")\n",
    "                if \"content\" not in msg:\n",
    "                    errors.append(f\"Line {line_num}, message {i+1}: Missing 'content'.\")\n",
    "                elif not isinstance(msg[\"content\"], str) or not msg[\"content\"].strip():\n",
    "                    errors.append(f\"Line {line_num}, message {i+1}: 'content' must be a non-empty string.\")\n",
    "\n",
    "    return errors if errors else \"✅ All lines are valid.\"\n",
    "\n",
    "result = validate_openai_chat_jsonl(\"oai_train_data1.jsonl\")\n",
    "print(result)\n",
    "\n",
    "result = validate_openai_chat_jsonl(\"oai_valid_data1.jsonl\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d614dd-0ddc-4bb4-9065-4394e88f1c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded File ID: file-1UazESknwdHCdJatYYZJpW\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "with open(\"oai_train_data1.jsonl\", \"rb\") as f:\n",
    "    file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "file_id = file.id\n",
    "print(f\"Uploaded File ID: {file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c6b17eb-4fd8-44c0-bd70-f9310acd81ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded File ID: file-VMvsbXQeDCQN5yKF6xEh5j\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "with open(\"oai_valid_data1.jsonl\", \"rb\") as f:\n",
    "    file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "file_id = file.id\n",
    "print(f\"Uploaded File ID: {file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d629f28-806a-4132-a817-f37de5657da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-bTgWawaHPNzVNPQvsF8R81do\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import random\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    training_file=\"file-1UazESknwdHCdJatYYZJpW\", \n",
    "    validation_file=\"file-VMvsbXQeDCQN5yKF6xEh5j\",\n",
    "    suffix=\"smart-4o-mini\"\n",
    ")\n",
    "\n",
    "print(f\"Job ID: {response.id}\")\n",
    "print(f\"Status: {response.status}\")\n",
    "# Job ID: ftjob-WqXCOaZ01ibj7nxC8guUBiGh\n",
    "# Status: validating_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0fac5b8-ce5e-419c-a01e-8c58cd3c7901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-bTgWawaHPNzVNPQvsF8R81do running\n",
      "ftjob-S2XwYn0eRkTcba01p1A4Nd5p failed\n",
      "ftjob-rl2nitrhY9J0fIcm1GHsjKWt failed\n",
      "ftjob-XyxRIzkdMQuncIuTnMZZZOSn failed\n",
      "ftjob-5aLF3brGyBq72SWfV972od5z failed\n",
      "ftjob-iqOpb0KlkdaeNVb1qKMaIZHn failed\n",
      "ftjob-hzeNJn4x4st8EOP1TtoQZrHx failed\n",
      "ftjob-7c9QSq1bX8As4ay8H0AHjxqV failed\n",
      "ftjob-SbOXIas4OlUSZsg13ac7H6h4 failed\n",
      "ftjob-BsdKsJK0SWQT5fGTmKF5ThFE failed\n",
      "ftjob-hSFOGkNM4vh8aeyY4gP0MEU3 failed\n",
      "ftjob-RsXIOdJ08IF281bvUKao4hj7 failed\n",
      "ftjob-kB2BXgrtyDlNaPNB1JcNra1d failed\n",
      "ftjob-WqXCOaZ01ibj7nxC8guUBiGh failed\n",
      "ftjob-jGcHGiIe8nV3IPcZ4dzMW9hD failed\n",
      "ftjob-f7ObGrkv3sAziHeJP2wVW5hI failed\n"
     ]
    }
   ],
   "source": [
    "# Job ID: ftjob-f7ObGrkv3sAziHeJP2wVW5hI\n",
    "# Status: validating_files\n",
    "\n",
    "response = client.fine_tuning.jobs.list()\n",
    "for job in response.data:\n",
    "    print(job.id, job.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f53d457-1955-42cc-83de-fe903bcdcd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n"
     ]
    }
   ],
   "source": [
    "job_id = \"ftjob-bTgWawaHPNzVNPQvsF8R81do\"\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "print(response.status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "600b3abd-6cd9-4bce-88e3-d0ce3f42a2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=1.8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40995145-91e9-4f3e-8458-c3a147ed2be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1748653210] The job has successfully completed\n",
      "[1748653202] Usage policy evaluations completed, model is now enabled for sampling\n",
      "[1748653202] Moderation checks for snapshot ft:gpt-4o-mini-2024-07-18:personal:smart-4o-mini:Bd4faLMY passed\n",
      "[1748652443] Evaluating model against our usage policies before enabling\n",
      "[1748652443] New fine-tuned model created\n",
      "[1748652442] Checkpoint created at step 1898\n",
      "[1748652442] Checkpoint created at step 949\n",
      "[1748652422] Step 2847/2847: training loss=0.37, validation loss=0.50, full validation loss=0.45\n",
      "[1748652403] Step 2846/2847: training loss=0.41\n",
      "[1748652401] Step 2845/2847: training loss=0.29\n",
      "[1748652401] Step 2844/2847: training loss=0.36\n",
      "[1748652401] Step 2843/2847: training loss=0.38\n",
      "[1748652398] Step 2842/2847: training loss=0.64\n",
      "[1748652398] Step 2841/2847: training loss=0.65\n",
      "[1748652395] Step 2840/2847: training loss=0.38\n",
      "[1748652395] Step 2839/2847: training loss=0.64\n",
      "[1748652395] Step 2838/2847: training loss=0.34\n",
      "[1748652392] Step 2837/2847: training loss=0.56\n",
      "[1748652392] Step 2836/2847: training loss=0.68\n",
      "[1748652392] Step 2835/2847: training loss=0.31\n",
      "[1748652389] Step 2834/2847: training loss=0.50\n",
      "[1748652389] Step 2833/2847: training loss=0.37\n",
      "[1748652389] Step 2832/2847: training loss=0.26\n",
      "[1748652387] Step 2831/2847: training loss=0.41\n",
      "[1748652387] Step 2830/2847: training loss=0.15\n",
      "[1748652386] Step 2829/2847: training loss=0.15\n",
      "[1748652384] Step 2828/2847: training loss=0.23\n",
      "[1748652384] Step 2827/2847: training loss=0.27\n",
      "[1748652384] Step 2826/2847: training loss=0.51\n",
      "[1748652381] Step 2825/2847: training loss=0.50\n",
      "[1748652381] Step 2824/2847: training loss=0.30\n",
      "[1748652381] Step 2823/2847: training loss=0.49\n",
      "[1748652378] Step 2822/2847: training loss=0.24\n",
      "[1748652378] Step 2821/2847: training loss=0.30\n",
      "[1748652378] Step 2820/2847: training loss=0.42\n",
      "[1748652375] Step 2819/2847: training loss=0.34\n",
      "[1748652375] Step 2818/2847: training loss=0.38\n",
      "[1748652372] Step 2817/2847: training loss=0.18\n",
      "[1748652372] Step 2816/2847: training loss=0.57\n",
      "[1748652372] Step 2815/2847: training loss=0.13\n",
      "[1748652372] Step 2814/2847: training loss=0.54\n",
      "[1748652369] Step 2813/2847: training loss=0.57\n",
      "[1748652369] Step 2812/2847: training loss=0.17\n",
      "[1748652369] Step 2811/2847: training loss=0.30\n",
      "[1748652366] Step 2810/2847: training loss=0.13\n",
      "[1748652366] Step 2809/2847: training loss=0.18\n",
      "[1748652366] Step 2808/2847: training loss=0.27\n",
      "[1748652364] Step 2807/2847: training loss=0.36\n",
      "[1748652364] Step 2806/2847: training loss=0.51\n",
      "[1748652361] Step 2805/2847: training loss=0.41\n",
      "[1748652361] Step 2804/2847: training loss=0.28\n",
      "[1748652358] Step 2803/2847: training loss=0.42\n",
      "[1748652358] Step 2802/2847: training loss=0.23\n",
      "[1748652358] Step 2801/2847: training loss=0.24\n",
      "[1748652355] Step 2800/2847: training loss=0.31, validation loss=0.62\n",
      "[1748652352] Step 2799/2847: training loss=0.30\n",
      "[1748652349] Step 2798/2847: training loss=0.26\n",
      "[1748652349] Step 2797/2847: training loss=0.32\n",
      "[1748652349] Step 2796/2847: training loss=0.28\n",
      "[1748652347] Step 2795/2847: training loss=0.14\n",
      "[1748652347] Step 2794/2847: training loss=0.11\n",
      "[1748652347] Step 2793/2847: training loss=0.19\n",
      "[1748652344] Step 2792/2847: training loss=0.44\n",
      "[1748652344] Step 2791/2847: training loss=0.26\n",
      "[1748652344] Step 2790/2847: training loss=0.39\n",
      "[1748652341] Step 2789/2847: training loss=0.32\n",
      "[1748652341] Step 2788/2847: training loss=0.28\n",
      "[1748652341] Step 2787/2847: training loss=0.33\n",
      "[1748652338] Step 2786/2847: training loss=0.85\n",
      "[1748652338] Step 2785/2847: training loss=0.36\n",
      "[1748652338] Step 2784/2847: training loss=0.34\n",
      "[1748652336] Step 2783/2847: training loss=0.24\n",
      "[1748652336] Step 2782/2847: training loss=0.33\n",
      "[1748652335] Step 2781/2847: training loss=0.43\n",
      "[1748652333] Step 2780/2847: training loss=0.53\n",
      "[1748652333] Step 2779/2847: training loss=0.54\n",
      "[1748652333] Step 2778/2847: training loss=0.57\n",
      "[1748652330] Step 2777/2847: training loss=0.19\n",
      "[1748652330] Step 2776/2847: training loss=0.31\n",
      "[1748652327] Step 2775/2847: training loss=0.38\n",
      "[1748652327] Step 2774/2847: training loss=0.29\n",
      "[1748652327] Step 2773/2847: training loss=0.39\n",
      "[1748652324] Step 2772/2847: training loss=0.38\n",
      "[1748652324] Step 2771/2847: training loss=0.31\n",
      "[1748652324] Step 2770/2847: training loss=0.26\n",
      "[1748652321] Step 2769/2847: training loss=0.48\n",
      "[1748652321] Step 2768/2847: training loss=0.43\n",
      "[1748652321] Step 2767/2847: training loss=0.63\n",
      "[1748652319] Step 2766/2847: training loss=0.37\n",
      "[1748652318] Step 2765/2847: training loss=0.55\n",
      "[1748652316] Step 2764/2847: training loss=0.54\n",
      "[1748652316] Step 2763/2847: training loss=0.30\n",
      "[1748652316] Step 2762/2847: training loss=0.51\n",
      "[1748652313] Step 2761/2847: training loss=0.51\n",
      "[1748652313] Step 2760/2847: training loss=0.31\n",
      "[1748652313] Step 2759/2847: training loss=0.41\n",
      "[1748652310] Step 2758/2847: training loss=0.29\n",
      "[1748652310] Step 2757/2847: training loss=0.43\n",
      "[1748652310] Step 2756/2847: training loss=0.30\n",
      "[1748652307] Step 2755/2847: training loss=0.52\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=100)\n",
    "\n",
    "for event in events.data:\n",
    "    print(f\"[{event.created_at}] {event.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32346931-45fa-4076-a8c8-3f190810a056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5de1f30f-d1b6-44b8-b04b-ec01386d0d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-tts\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-transcribe\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "    if model.id.startswith(\"gpt-4o-mini\"):\n",
    "        print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "144be015-4285-4a09-9fde-93c393884c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "curl: (35) schannel: next InitializeSecurityContext failed: CRYPT_E_NO_REVOCATION_CHECK (0x80092012) - The revocation function was unable to check revocation for the certificate.\n"
     ]
    }
   ],
   "source": [
    "!curl https://api.openai.com/v1/fine_tuning/model_limits -H \"Authorization: Bearer $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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca07ba-6aa2-4440-8ae4-5d6baac09e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

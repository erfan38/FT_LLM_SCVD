{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7090759-dbfb-46f6-86cf-f93b7f1c4f89",
   "metadata": {},
   "source": [
    "# TODO\n",
    "---\n",
    "1. Convert codes from list to string\n",
    "---\n",
    "2. Contract line numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff32722c-7f90-441e-87df-bc2de67ea36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, sys\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..','..'))\n",
    "sys.path.append(project_root)\n",
    "from config.keys import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa1da741-4264-4d47-b1ce-e744ec50975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbered_contract(contract):\n",
    "        lines = contract.split(\"\\n\")\n",
    "        numbered_lines = [f\"{i+1}: {line}\" for i, line in enumerate(lines)]\n",
    "        return \"\\n\".join(numbered_lines)\n",
    "    \n",
    "class Generator:\n",
    "    def __init__(self, vulnerability, schema):\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        self.vulnerability = vulnerability\n",
    "        self.schema = schema\n",
    "        self.message = []\n",
    "        if \"Timestamp Dependency\" in vulnerability:\n",
    "            documentation_file = \"TD_instruction.txt\"\n",
    "        elif \"Integer overflow/underflow\" in vulnerability:\n",
    "            documentation_file = \"IoU_instruction.txt\"\n",
    "        elif \"Reentrancy\" in vulnerability:\n",
    "            documentation_file = \"RE_instruction.txt\"\n",
    "        with open(os.path.join(\"documentation\", documentation_file), \"r\") as f:\n",
    "            self.documentation = f.read()\n",
    "        self.system_message = {\"role\":\"system\",\"content\":\"You are a cyber-security programmer that can detect vulnerable lines of the contract based on the instruction.\"}\n",
    "        self.user_prefix = f\"\"\"In the code below, detect {vulnerability} vulnerabilities and provide extra information regarding the vulnerable code snippet based on the given instruction\"\"\"\n",
    "        self.output_formatter = \"\"\"[\n",
    "   {\"vulnerableLines\": \"l1-l2\",\n",
    "    \"vulnerableCode\": \"<a list containing lines of vulnerable piece of code>\"\n",
    "    \"vulnerabilityReason\": \"<Reasons of the ulnerability of lines l1 to l2>\",\n",
    "    \"potentialSecurityRisk\": \"<Potential risks the vulneraility causes>\",\n",
    "    \"fixedCode\": \"<the healthy code snippet>\"\n",
    "  }\n",
    "  ...\n",
    "  ]\"\"\"\n",
    "        self.formatter = f\"Return the response in RFC8259 compliant JSON according to the ResponseFormat schema with no other text. Follow the example format:\\n{self.output_formatter}\"\n",
    "\n",
    "    \n",
    "    def set_target_vulnerability(self, vulnerability):\n",
    "        self.vulnerability = vulnerability\n",
    "        \n",
    "    def update_message(self, new_message):\n",
    "        self.message.append(new_message)\n",
    "        \n",
    "    def get_user_message(self, code, instruction, helper):\n",
    "        self.user_content = f\"\"\"\n",
    "{self.user_prefix}\n",
    "\n",
    "Instruction:\n",
    "{instruction}\n",
    "\n",
    "Here is the vulnerable lines:\n",
    "{helper}\n",
    "-----------------\n",
    "Smart Contract Code:\n",
    "{code}\n",
    "\n",
    "-----------------\n",
    "{self.output_formatter}\n",
    "###\n",
    "        \"\"\"\n",
    "# -----------------\n",
    "# {self.formatter}\n",
    "        user_message = {\"role\": \"user\", \"content\":self.user_content}\n",
    "        return user_message\n",
    "\n",
    "    def get_example_message(self, example_data):\n",
    "        train_code, instruction, train_response, helper = map_example(example_data)\n",
    "        numbered_train_code = get_numbered_contract(train_code)\n",
    "\n",
    "        train_user_message = self.get_user_message(numbered_train_code, instruction, helper)\n",
    "        train_assistant_message = {\"role\": \"assistant\", \"content\": str(train_response)}\n",
    "        return [train_user_message, train_assistant_message]\n",
    "        \n",
    "\n",
    "    def create_prompt(self, train_data, code, instruction, helper):\n",
    "        self.message = []\n",
    "        self.message.append(self.system_message)\n",
    "        self.message.append({\"role\": \"user\", \"content\":self.documentation})\n",
    "        for example_data in train_data:\n",
    "            self.message.extend(self.get_example_message(example_data))        # \n",
    "        self.message.append(self.get_user_message(get_numbered_contract(code), instruction, helper))\n",
    "\n",
    "    # def generate(self):\n",
    "    #     done = False\n",
    "    #     while not done:\n",
    "    #         try:\n",
    "    #             completion = self.completion_with_backoff(model=\"gpt-4o\", \n",
    "    #                                       messages=self.message,\n",
    "    #                                       temperature=1,\n",
    "    #                                       max_tokens=4096,\n",
    "    #                                       top_p=1.,\n",
    "    #                                       frequency_penalty=0,\n",
    "    #                                       presence_penalty=0)\n",
    "        \n",
    "        \n",
    "    #             answer = completion.choices[0].message.content\n",
    "    #             done = True\n",
    "    #         except RateLimitError:\n",
    "    #             time.sleep(60)\n",
    "    #             print(\"Rate limit exceeded. Paused for 60 seconds!\")\n",
    "                \n",
    "    #     return answer, completion\n",
    "        \n",
    "    def generate(self):\n",
    "        done = False\n",
    "        i=0\n",
    "        while not done:\n",
    "            try:\n",
    "                if i==5:\n",
    "                    done=True\n",
    "                completion = self.client.beta.chat.completions.parse(\n",
    "                              model=\"gpt-4o-mini\",\n",
    "                              messages = self.message,\n",
    "                              response_format=self.schema\n",
    "                            )\n",
    "                answer = json.loads(completion.choices[0].message.content)\n",
    "                done = True\n",
    "                i+=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Rate limit exceeded. Paused for 120 seconds!\")\n",
    "        return answer, completion\n",
    "\n",
    "\n",
    "def read_json_files(fewshot_dir, loc_dir):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(fewshot_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(fewshot_dir, filename)\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            with open(os.path.join(loc_dir, filename), 'r') as f:\n",
    "                fewshot_helper = json.load(f)\n",
    "                # print(\"FEWSHOT HELPER\")\n",
    "                # print(fewshot_helper)\n",
    "            data.append({\"helper\": fewshot_helper})\n",
    "            # print(\"FS DATA\")\n",
    "            # print(data)\n",
    "            all_data.append(data)\n",
    "    return all_data\n",
    "\n",
    "def map_example(example_data):\n",
    "\n",
    "    if not example_data or len(example_data) < 1:\n",
    "        raise ValueError(\"example_data must contain at least one element.\")\n",
    "\n",
    "    train_code = example_data[0][\"input\"]\n",
    "    instruction = example_data[0][\"output\"]\n",
    "    train_response = example_data[1:-1]\n",
    "    start_line = example_data[1][\"vulnerableLines\"]\n",
    "    helper = example_data[-1]\n",
    "    return train_code, instruction, train_response, helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62199e99-f396-4f9a-a85e-43a3a1034c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = [\n",
    "#     {\"dataset_name\":\"ESC_timestamp\", \n",
    "#      \"vulnerability\": \"Timestamp Dependency\"}\n",
    "#     ]\n",
    "# dataset = [\n",
    "#     {\"dataset_name\": \"source3_integeroverflow\",\n",
    "#            \"vulnerability\": \"Integer overflow/underflow\"}\n",
    "#  ]\n",
    "dataset = [\n",
    "    {\"dataset_name\":\"source3_reentrancy\", \n",
    "     \"vulnerability\": \"Reentrancy\"}\n",
    "    ]\n",
    "end_sample_num = 630 # for smartbugs, we only get 629 vulnerable code, not 1078."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01e91d49-f2ee-4cab-88a8-cca3bb5af072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full_source2_reentrancy_218: instead of input--> contract, instead of output--> target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7318b6-b544-4041-b368-55845967a7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class SingleVulnerability(BaseModel):\n",
    "    vulnerableLines: str\n",
    "    vulnerableCode: List[str]\n",
    "    vulnerabilityReason: str=Field(description='Why the code snippet is vulnerable') \n",
    "    potentialSecurityRisk: str=Field(description='The potential security risk the vulnerability may cause.') \n",
    "    fixedCode: str=Field(description='The healthy code snippet, not the way to fix ') \n",
    "\n",
    "class FullVulnerability(BaseModel):\n",
    "    vulnerabilities: List[SingleVulnerability]\n",
    "\n",
    "\n",
    "\n",
    "dataset_name = dataset[0][\"dataset_name\"]\n",
    "vulnerability =dataset[0][\"vulnerability\"]\n",
    "raw_fname = os.path.join(\"..\", \"..\", \"..\",\"data\", \"dataset\", \"raw\", dataset_name+\".json\")\n",
    "fewshot_dir = os.path.join(\"..\", \"..\", \"..\",\"data\", \"dataset\", \"few_shots\", dataset_name)\n",
    "processed_dir = os.path.join(\"..\", \"..\", \"..\",\"data\", \"dataset\", \"processed_data\", dataset_name)\n",
    "loc_dir = os.path.join(\"..\", \"..\", \"..\",\"data\", \"processed_data\", dataset_name, \"LOCs\")\n",
    "os.makedirs(loc_dir, exist_ok=True)\n",
    "loc_helper_dir = os.path.join(\"..\", \"..\", \"..\",\"data\", \"processed_data\", dataset_name, \"LOCs_old\")\n",
    "\n",
    "fewshot_data = read_json_files(fewshot_dir, loc_helper_dir)\n",
    "# print(fewshot_data[0])\n",
    "print(raw_fname)\n",
    "with open(raw_fname, 'r', encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "schema = FullVulnerability\n",
    "for i, raw_record in enumerate(raw_data[:end_sample_num]): # [:end_sample_num]\n",
    "    if raw_record[\"target\"][0] == \"0\":\n",
    "        print(f\"Contract {i} is marked as healthy - skipping\")\n",
    "        continue\n",
    "    if f\"{i}.json\" in os.listdir(loc_dir):\n",
    "        print(f\"Contract {i} is already processed - skipping\")\n",
    "        continue\n",
    "    with open(os.path.join(loc_helper_dir, f\"{i}.json\"), 'r') as f:\n",
    "        helper = json.load(f)\n",
    "    print(f\"Contract {i} is Being  processed :)\")\n",
    "    \n",
    "    generator = Generator(vulnerability, schema)\n",
    "    prompt = generator.create_prompt(fewshot_data, code=raw_record[\"input\"], instruction=raw_record[\"output\"], helper=helper)\n",
    "    response, completions = generator.generate()\n",
    "    answer = json.loads(completions.choices[0].message.content)\n",
    "    with open(os.path.join(loc_dir, f\"{i}.json\"), \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(answer, file, ensure_ascii=False, indent=4)\n",
    "    #break\n",
    "print(\"Done!\")\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# locs_dir = os.path.join(output_dir, \"LOCs\")\n",
    "# os.makedirs(locs_dir, exist_ok=True)\n",
    "# contracts_dir = os.path.join(output_dir, \"contracts\")\n",
    "# os.makedirs(contracts_dir, exist_ok=True)\n",
    "# raw_dir = \"../../data/dataset/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07141f8-eb54-45b6-917f-6483105c9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = json.loads(completions.choices[0].message.content)\n",
    "# answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d1321-b0b2-4c87-aba7-792af11e0fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09357c9c-57d8-475f-a263-4be19ef4bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generator.message[6]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738f8b4-376f-49cd-a880-861bbea23ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe684e-c27f-4bdc-84c8-9f44f5c18e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95183384-47a5-4f06-9680-326997fd192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### **adapt to the SmartAudit datasets : IoU,RE,TD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee047657-4ed0-4579-993c-fc170cfbc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, sys\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "from config.keys import OPENAI_API_KEY\n",
    "\n",
    "def get_numbered_contract(contract):\n",
    "    \"\"\"Number each line of the smart contract for easier reference.\"\"\"\n",
    "    lines = contract.split(\"\\n\")\n",
    "    numbered_lines = [f\"{i+1}: {line}\" for i, line in enumerate(lines)]\n",
    "    return \"\\n\".join(numbered_lines)\n",
    "\n",
    "class SingleVulnerability(BaseModel):\n",
    "    vulnerableLines: str\n",
    "    vulnerableCode: list\n",
    "    vulnerabilityReason: str = Field(description=\"Why the code snippet is vulnerable\") \n",
    "    potentialSecurityRisk: str = Field(description=\"Potential security risks caused by this vulnerability\") \n",
    "    fixedCode: str = Field(description=\"A secure version of the vulnerable code\") \n",
    "\n",
    "class FullVulnerability(BaseModel):\n",
    "    vulnerabilities: list[SingleVulnerability]\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, vulnerability, schema):\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        self.vulnerability = vulnerability\n",
    "        self.schema = schema\n",
    "        self.message = []\n",
    "        \n",
    "        if \"Timestamp Dependency\" in vulnerability:\n",
    "            documentation_file = \"TD_instruction.txt\"\n",
    "        elif \"Integer overflow/underflow\" in vulnerability:\n",
    "            documentation_file = \"IoU_instruction.txt\"\n",
    "        elif \"Reentrancy\" in vulnerability:\n",
    "            documentation_file = \"RE_instruction.txt\"\n",
    "        \n",
    "        with open(os.path.join(\"documentation\", documentation_file), \"r\") as f:\n",
    "            self.documentation = f.read()\n",
    "        \n",
    "        self.system_message = {\"role\": \"system\", \"content\": \"You are a cyber-security programmer that can detect vulnerable lines of the contract based on the instruction.\"}\n",
    "        self.user_prefix = f\"\"\"In the code below, detect {vulnerability} vulnerabilities and provide extra information regarding the vulnerable code snippet based on the given instruction.\"\"\"\n",
    "        \n",
    "        self.output_formatter = \"\"\"[\n",
    "            {\"vulnerableLines\": \"l1-l2\",\n",
    "            \"vulnerableCode\": \"<a list containing lines of vulnerable piece of code>\",\n",
    "            \"vulnerabilityReason\": \"<Reasons for the vulnerability of lines l1 to l2>\",\n",
    "            \"potentialSecurityRisk\": \"<Potential risks the vulnerability causes>\",\n",
    "            \"fixedCode\": \"<The corrected secure code snippet>\"\n",
    "            }\n",
    "        ]\"\"\"\n",
    "        \n",
    "        self.formatter = f\"Return the response in RFC8259 compliant JSON according to the ResponseFormat schema with no other text. Follow the example format:\\n{self.output_formatter}\"\n",
    "\n",
    "    def update_message(self, new_message):\n",
    "        self.message.append(new_message)\n",
    "\n",
    "    def get_user_message(self, code, helper):\n",
    "        \"\"\"Generate the user prompt without an `output` field.\"\"\"\n",
    "        self.user_content = f\"\"\"\n",
    "{self.user_prefix}\n",
    "\n",
    "Here is the vulnerable lines:\n",
    "{helper}\n",
    "-----------------\n",
    "Smart Contract Code:\n",
    "{code}\n",
    "\n",
    "-----------------\n",
    "{self.output_formatter}\n",
    "###\n",
    "        \"\"\"\n",
    "        user_message = {\"role\": \"user\", \"content\": self.user_content}\n",
    "        return user_message\n",
    "\n",
    "    def create_prompt(self, train_data, code, helper):\n",
    "        \"\"\"Create the prompt based on training data and current contract.\"\"\"\n",
    "        self.message = []\n",
    "        self.message.append(self.system_message)\n",
    "        self.message.append({\"role\": \"user\", \"content\": self.documentation})\n",
    "        \n",
    "        for example_data in train_data:\n",
    "            self.message.extend(self.get_example_message(example_data)) \n",
    "        \n",
    "        self.message.append(self.get_user_message(get_numbered_contract(code), helper))\n",
    "\n",
    "    def get_example_message(self, example_data):\n",
    "        \"\"\"Prepare few-shot examples.\"\"\"\n",
    "        train_code, train_response, helper = map_example(example_data)\n",
    "        numbered_train_code = get_numbered_contract(train_code)\n",
    "        \n",
    "        train_user_message = self.get_user_message(numbered_train_code, helper)\n",
    "        train_assistant_message = {\"role\": \"assistant\", \"content\": str(train_response)}\n",
    "        return [train_user_message, train_assistant_message]\n",
    "\n",
    "    def generate(self):\n",
    "        \"\"\"Generate vulnerability analysis using GPT.\"\"\"\n",
    "        done = False\n",
    "        i = 0\n",
    "        while not done:\n",
    "            try:\n",
    "                if i == 5:\n",
    "                    done = True\n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=self.message,\n",
    "                    response_format=self.schema  # ✅ Using schema as in original code\n",
    "                )\n",
    "                answer = json.loads(completion.choices[0].message.content)\n",
    "                done = True\n",
    "                i += 1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Rate limit exceeded. Paused for 120 seconds!\")\n",
    "                time.sleep(120)\n",
    "        return answer, completion\n",
    "\n",
    "def read_json_files(fewshot_dir, loc_dir):\n",
    "    \"\"\"Read and load few-shot examples.\"\"\"\n",
    "    all_data = []\n",
    "    for filename in os.listdir(fewshot_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(fewshot_dir, filename)\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            with open(os.path.join(loc_dir, filename), 'r') as f:\n",
    "                fewshot_helper = json.load(f)\n",
    "            data.append({\"helper\": fewshot_helper})\n",
    "            all_data.append(data)\n",
    "    return all_data\n",
    "\n",
    "def map_example(example_data):\n",
    "    \"\"\"Extract training data from few-shot examples.\"\"\"\n",
    "    if not example_data or len(example_data) < 1:\n",
    "        raise ValueError(\"example_data must contain at least one element.\")\n",
    "\n",
    "    train_code = example_data[0][\"input\"]\n",
    "    train_response = example_data[1:-1]\n",
    "    helper = example_data[-1]\n",
    "    return train_code, train_response, helper\n",
    "\n",
    "# Define dataset structure\n",
    "dataset = [\n",
    "    {\"dataset_name\": \"IoU_FTSmartAudit_datasets\", \n",
    "     \"vulnerability\": \"Reentrancy\"}\n",
    "]\n",
    "\n",
    "end_sample_num = 2  # Limit processing to the first two contracts\n",
    "\n",
    "# Define directory paths\n",
    "dataset_name = dataset[0][\"dataset_name\"]\n",
    "vulnerability = dataset[0][\"vulnerability\"]\n",
    "\n",
    "raw_fname = os.path.join(\"..\", \"..\", \"..\", \"data\", \"dataset\", \"raw\", dataset_name + \".json\")\n",
    "fewshot_dir = os.path.join(\"..\", \"..\", \"..\", \"data\", \"dataset\", \"few_shots\", dataset_name)\n",
    "processed_dir = os.path.join(\"..\", \"..\", \"..\", \"data\", \"dataset\", \"processed_data\", dataset_name)\n",
    "loc_dir = os.path.join(\"..\", \"..\", \"..\", \"data\", \"processed_data\", dataset_name, \"LOCs\")\n",
    "os.makedirs(loc_dir, exist_ok=True)\n",
    "loc_helper_dir = os.path.join(\"..\", \"..\", \"..\", \"data\", \"processed_data\", dataset_name, \"LOCs_old\")\n",
    "\n",
    "# Load few-shot examples\n",
    "fewshot_data = read_json_files(fewshot_dir, loc_helper_dir)\n",
    "\n",
    "print(raw_fname)\n",
    "with open(raw_fname, 'r', encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "schema = FullVulnerability  # ✅ Using schema directly\n",
    "\n",
    "# Process each contract\n",
    "for i, raw_record in enumerate(raw_data[:end_sample_num]):  \n",
    "    output_filename = os.path.join(loc_dir, f\"{i}.json\")\n",
    "    \n",
    "    if os.path.exists(output_filename):\n",
    "        print(f\"Contract {i} is already processed - skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(loc_helper_dir, f\"{i}.json\"), 'r') as f:\n",
    "        helper = json.load(f)\n",
    "\n",
    "    print(f\"Processing contract {i}...\")\n",
    "\n",
    "    generator = Generator(vulnerability, schema)\n",
    "    generator.create_prompt(fewshot_data, code=raw_record[\"input\"], helper=helper)\n",
    "    response, completions = generator.generate()\n",
    "\n",
    "    if response:\n",
    "        with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(response, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7c104-6e0c-4316-b580-94519d584d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c61ce-401d-4b72-936a-943b6cc95f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdc24a-0942-47eb-826f-60f68b0aee1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828bece-5e23-441b-8b1c-2d559d627bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0427276-a2fa-4422-90b9-25acd4c74a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb0e91-de31-4aa6-922f-77e340644000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### i checked some code section in original json file, needed to be modified as they are not precise ! \n",
    "##  in the following code we are modifying the code section based on new start and end lines in the new sol files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bf51969-ea92-407c-9212-43393f395234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total contracts in dataset: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Contracts: 100%|██████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 500.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed contract 0 (time_manipulation): Updated LOC info with bias 7.\n",
      "Processed contract 1 (time_manipulation): Updated LOC info with bias 6.\n",
      "Processed contract 2 (time_manipulation): Updated LOC info with bias 6.\n",
      "Processed contract 3 (time_manipulation): Updated LOC info with bias 6.\n",
      "Processed contract 4 (time_manipulation): Updated LOC info with bias 6.\n",
      "Processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Configuration ===\n",
    "dataset_name = \"TD_FTSmartAudit_datasets\"\n",
    "raw_dir = \"../../data/dataset/raw\"\n",
    "json_file_path = os.path.join(raw_dir, f\"{dataset_name}.json\")\n",
    "# New base directory for final processed data\n",
    "base_output_dir = f\"../../data/processed_data/{dataset_name}/final/\"\n",
    "\n",
    "# Define the vulnerability type we want to process.\n",
    "desired_vuln_types = \"time_manipulation\"\n",
    "vuln = desired_vuln_types\n",
    "\n",
    "# New directories for saving processed contracts and LOC info.\n",
    "contracts_dir = os.path.join(base_output_dir, vuln, \"contracts\")\n",
    "new_locs_dir = os.path.join(base_output_dir, vuln, \"LOCs\")\n",
    "os.makedirs(contracts_dir, exist_ok=True)\n",
    "os.makedirs(new_locs_dir, exist_ok=True)\n",
    "\n",
    "# Existing LOCs are stored in a different directory.\n",
    "existing_locs_dir = os.path.join(\"../../data/processed_data\", dataset_name, \"LOCs\")\n",
    "\n",
    "# --- Load dataset ---\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(f\"Total contracts in dataset: {len(data)}\")\n",
    "end_contract = len(data)\n",
    "\n",
    "for idx, record in tqdm(enumerate(data[:end_contract]), total=end_contract, desc=\"Processing Contracts\"):\n",
    "    vuln_type = record.get(\"Vulnerability Type\", \"\").strip().lower()\n",
    "    contracts_dir = os.path.join(base_output_dir, vuln_type, \"contracts\")\n",
    "    new_locs_dir = os.path.join(base_output_dir, vuln_type, \"LOCs\")\n",
    "    os.makedirs(contracts_dir, exist_ok=True)\n",
    "    os.makedirs(new_locs_dir, exist_ok=True)\n",
    "\n",
    "    source_code_full = record.get(\"Source Code\", \"\")\n",
    "    input_code = record.get(\"input\", \"\")\n",
    "    \n",
    "    if not input_code:\n",
    "        print(f\"Skipping contract {idx}: No input found.\")\n",
    "        continue\n",
    "\n",
    "    contract_filename = f\"{idx}.sol\"\n",
    "    contract_path = os.path.join(contracts_dir, contract_filename)\n",
    "    with open(contract_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(input_code)\n",
    "\n",
    "    source_lines = source_code_full.split(\"\\n\")\n",
    "    input_lines_list = input_code.split(\"\\n\")\n",
    "    \n",
    "    # Compute the bias as the number of lines before the first \"pragma\" statement\n",
    "    bias = 0\n",
    "    for i, line in enumerate(source_lines):\n",
    "        if \"pragma\" in line:\n",
    "            bias = i\n",
    "            break\n",
    "    \n",
    "    existing_vuln_json_path = os.path.join(existing_locs_dir, f\"{idx}.json\")\n",
    "    if not os.path.exists(existing_vuln_json_path):\n",
    "        print(f\"Skipping contract {idx}: Vulnerability LOC file not found in existing LOCs folder.\")\n",
    "        continue\n",
    "\n",
    "    with open(existing_vuln_json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        vulnerability_info = json.load(json_file)\n",
    "    \n",
    "    for block in vulnerability_info:\n",
    "        original_start = block.get(\"start_line\")\n",
    "        original_end = block.get(\"end_line\")\n",
    "        if original_start is None or original_end is None:\n",
    "            continue\n",
    "        \n",
    "        new_start = original_start - bias\n",
    "        new_end = original_end - bias\n",
    "        \n",
    "        block[\"start_line\"] = new_start\n",
    "        block[\"end_line\"] = new_end\n",
    "        block[\"code\"] = input_lines_list[new_start - 1:new_end]\n",
    "    \n",
    "    new_vuln_json_path = os.path.join(new_locs_dir, f\"{idx}.json\")\n",
    "    with open(new_vuln_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(vulnerability_info, json_file, indent=4)\n",
    "\n",
    "    print(f\"Processed contract {idx} ({vuln_type}): Updated LOC info with bias {bias}.\")\n",
    "\n",
    "print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7514b24-3948-44b1-ab2e-e65f0a1918c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
